{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers.experimental import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Make Dataset</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23, 640, 640)\n",
      "(16, 23, 640, 640)\n",
      "(16, 1)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "img =  np.zeros((100,100,3))
    "img_resize = np.array(img)\n",
    "img_resize[:,:,0][np.newaxis,...].shape\n",
    "\n",
    "x_train = np.tile(img_resize[:,:, 0][np.newaxis,...], (22,1,1))\n",
    "x_train = np.concatenate((x_train, img_resize[:,:,2][np.newaxis,...]))\n",
    "print(x_train.shape)\n",
    "x_train = np.tile(x_train[np.newaxis, ...], (16,1,1,1))\n",
    "print(x_train.shape)\n",
    "\n",
    "x_train = x_train[..., np.newaxis]\n",
    "x_train = np.concatenate((x_train, x_train), axis = 4)\n",
    "img = np.transpose(x_train, (0,1,4,2,3))\n",
    "\n",
    "y_train = np.zeros(16).reshape(16,1)\n",
    "print(y_train.shape)\n",
    "\n",
    "img = np.transpose(img, (0,1,3,4,2))\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Make Generator</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "#augment generator\n",
    "def aug_gen(IMG_SIZE, seed):\n",
    "    aug_gen = tf.keras.Sequential([\n",
    "#     layers.experimental.preprocessing.Resizing(IMG_SIZE, IMG_SIZE),\n",
    "#     layers.experimental.preprocessing.Rescaling(1./255),\n",
    "    layers.experimental.preprocessing.RandomRotation(0.5, seed = seed)\n",
    "    ])\n",
    "    return aug_gen\n",
    "\n",
    "def augment_images(images, IMG_SIZE, seed):\n",
    "    data_augmentation = aug_gen(IMG_SIZE, seed)\n",
    "    a = [*map(lambda x: data_augmentation(x[np.newaxis, ...], training=True), images)]\n",
    "    result = np.array(a)\n",
    "    return result #(1, px, px, channel)\n",
    "\n",
    "def multi_gen(img, y, t, gen_num, seed):\n",
    "    x1 = augment_images(img, IMG_SIZE, seed) #(num, 1, px, px, channel)\n",
    "    y1 = y #(num, 1)\n",
    "    last_num = gen_num-img.shape[0]*t\n",
    "    if t > 1:\n",
    "        for i in range(t - 1):\n",
    "            if i == t - 2:\n",
    "                img = img[:last_num]            \n",
    "            x2 = augment_images(img, IMG_SIZE, i + 1) #(1, px, px, channel)\n",
    "            # 画像は nparray, ラベルは tf.Tensorを要素とする配列にする\n",
    "            x1 = np.concatenate([x1, x2])\n",
    "            y1 = tf.concat([y1, y], axis = 0)\n",
    "\n",
    "    result = (x1[:gen_num], y1[:gen_num])\n",
    "    return result\n",
    "\n",
    "def separate_axis(img):\n",
    "    sep0 = np.squeeze(np.transpose(img[...,[0]], (0,4,2,3,1)))\n",
    "    sep1 = np.squeeze(np.transpose(img[...,[1]], (0,4,2,3,1)))\n",
    "    return sep0, sep1\n",
    "    \n",
    "def concat_gen(img, y_train, gen_num, IMG_SIZE, seed):\n",
    "    t = gen_num//img.shape[0] + 1\n",
    "    print(gen_num, img.shape[0], t)\n",
    "    sep0, sep1 = separate_axis(img)\n",
    "    r0 = multi_gen(sep0, y_train, t, gen_num, seed)\n",
    "    r1 = multi_gen(sep1, y_train, t, gen_num, seed)\n",
    "    concat_x = np.transpose(np.concatenate((r0[0],r1[0]), axis =1), (0,4,2,3,1))\n",
    "    concat_y = r0[1]\n",
    "    print(concat_x.shape, concat_y.shape)\n",
    "    return concat_x, concat_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset generator\n",
    "def resize_and_rescale(IMG_SIZE):\n",
    "    resres = tf.keras.Sequential([\n",
    "    layers.experimental.preprocessing.Resizing(IMG_SIZE, IMG_SIZE),\n",
    "    layers.experimental.preprocessing.Rescaling(1./255)])\n",
    "    return resres\n",
    "def create_resres(img, y_train, IMG_SIZE):\n",
    "    sep0, sep1 = separate_axis(img)\n",
    "    resres = resize_and_rescale(IMG_SIZE)\n",
    "    res0 = [*map(lambda x: resres(x[np.newaxis, ...], training=True), sep0)]\n",
    "    res1 = [*map(lambda x: resres(x[np.newaxis, ...], training=True), sep1)]\n",
    "    res0 = np.array(res0)\n",
    "    res1 = np.array(res1)\n",
    "    result = np.transpose(np.concatenate((res0, res1),axis = 1), (0,4,2,3,1))\n",
    "    return result, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use tf.data\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "def prepare(img, y_train, shuffle=False, augment=False):\n",
    "    img, y_train = create_resres(img, y_train, IMG_SIZE)\n",
    "    print(img.shape)\n",
    "    if augment:\n",
    "        ds_x, ds_y = concat_gen(img, y_train, gen_num, IMG_SIZE, seed)\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((ds_x, ds_y))\n",
    "    else:\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((img, y_train))\n",
    "    if shuffle:\n",
    "        train_dataset_dataset = train_dataset.shuffle(1000)\n",
    "    \n",
    "    # Batch all datasets\n",
    "    train_dataset = train_dataset.batch(batch_size)\n",
    "    return train_dataset.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 23, 79, 79, 2)\n",
      "100 16 7\n",
      "(100, 23, 79, 79, 2) (100, 1)\n",
      "(5, 23, 79, 79, 2)\n",
      "(5, 23, 79, 79, 2)\n",
      "<PrefetchDataset shapes: ((None, 23, 79, 79, 2), (None, 1)), types: (tf.float32, tf.float64)>\n"
     ]
    }
   ],
   "source": [
    "train_ds = prepare(img, y_train, shuffle=True, augment=True)\n",
    "val_ds = prepare(img[:5], y_train[:5])\n",
    "test_ds = prepare(img[:5], y_train[:5])\n",
    "print(train_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Define MODEL</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_3d():\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense, Dropout, Flatten\n",
    "    from keras.layers import Conv3D, MaxPooling3D\n",
    "    from tensorflow.keras.optimizers import Adam\n",
    "    from keras.initializers import uniform,lecun_uniform,normal,identity,orthogonal,zero,glorot_normal,glorot_uniform,he_normal,he_uniform,lecun_normal, lecun_uniform\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv3D(4, (3, 3, 3), strides=(2, 2, 2), activation='relu', input_shape=(23, 79, 79, 2), kernel_initializer=\"random_normal\"))\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "             optimizer=\"adam\",\n",
    "             metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN_3d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Set Hyperparameter</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 79\n",
    "seed = 1\n",
    "gen_num = 100\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "100/100 [==============================] - 4s 39ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 3s 33ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 3s 33ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "epochs=5\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
